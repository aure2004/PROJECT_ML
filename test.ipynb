{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b532c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "# Ignorer les avertissements de convergence pour plus de clarté\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # Pour certains warnings de scikit-learn\n",
    "\n",
    "# --- 1. Charger les données ---\n",
    "try:\n",
    "    # Assure-toi que le fichier CSV est dans le même répertoire que ton notebook,\n",
    "    # ou ajuste le chemin d'accès.\n",
    "    df = pd.read_csv('electric_vehicle_analytics.csv', delimiter=',') # \n",
    "    print(\"Données chargées avec succès !\")\n",
    "    print(f\"Dimensions du DataFrame : {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erreur : Le fichier 'electric_vehicle_analytics.csv' n'a pas été trouvé.\")\n",
    "    exit() # Arrête le script si le fichier n'est pas trouvé\n",
    "\n",
    "# Afficher les premières lignes et les informations générales\n",
    "print(\"\\n--- Aperçu des données ---\")\n",
    "print(df.head())\n",
    "print(\"\\n--- Informations sur les colonnes et types de données ---\")\n",
    "df.info()\n",
    "\n",
    "# --- 2. Analyse Exploratoire (focus sur la cible) ---\n",
    "print(\"\\n--- Statistiques descriptives de la variable cible (Range_km) ---\")\n",
    "print(df['Range_km'].describe())\n",
    "\n",
    "print(\"\\n--- Visualisation de la distribution de la variable cible (Range_km) ---\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Range_km'], kde=True)\n",
    "plt.title('Distribution de l\\'autonomie (Range_km)')\n",
    "plt.xlabel('Autonomie (km)')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.show()\n",
    "# Commentaire : Observer la forme de la distribution (symétrie, asymétrie, pics, etc.)\n",
    "\n",
    "# --- 3. Prétraitement des données ---\n",
    "print(\"\\n--- Prétraitement des données ---\")\n",
    "\n",
    "# Séparer les caractéristiques (X) et la cible (y)\n",
    "X = df.drop('Range_km', axis=1)\n",
    "y = df['Range_km']\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles (exclure l'ID et potentiellement Model)\n",
    "# Note: On exclut 'Model' car il a trop de valeurs uniques pour OHE simple.\n",
    "# Tu pourrais explorer d'autres techniques d'encodage si 'Model' est important.\n",
    "numerical_features = X.select_dtypes(include=np.number).drop('Vehicle_ID', axis=1, errors='ignore').columns.tolist()\n",
    "categorical_features = ['Make', 'Region', 'Vehicle_Type', 'Usage_Type'] # Exclut Model pour cet exemple\n",
    "\n",
    "print(f\"Caractéristiques numériques sélectionnées : {numerical_features}\")\n",
    "print(f\"Caractéristiques catégorielles sélectionnées : {categorical_features}\")\n",
    "\n",
    "# Créer les transformateurs\n",
    "# Mise à l'échelle pour les numériques, One-Hot Encoding pour les catégorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features) # ignore les catégories non vues à l'entraînement\n",
    "    ],\n",
    "    remainder='drop' # Ignore les autres colonnes (comme 'Model')\n",
    ")\n",
    "\n",
    "# --- 4. Séparation Entraînement / Test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Taille de l'ensemble d'entraînement : {X_train.shape[0]} échantillons\")\n",
    "print(f\"Taille de l'ensemble de test : {X_test.shape[0]} échantillons\")\n",
    "\n",
    "# --- 5. Création et Entraînement du Pipeline (Modèle RandomForestRegressor) ---\n",
    "# Utilisation d'un pipeline pour intégrer le prétraitement et le modèle\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))]) # n_jobs=-1 utilise tous les processeurs\n",
    "\n",
    "print(\"\\n--- Entraînement du modèle RandomForestRegressor ---\")\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "print(\"Entraînement terminé.\")\n",
    "\n",
    "# --- 6. Évaluation sur l'ensemble de test ---\n",
    "print(\"\\n--- Évaluation sur l'ensemble de test ---\")\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calcul des métriques de régression\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} km\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} km\")\n",
    "print(f\"Coefficient de détermination (R²): {r2:.3f}\")\n",
    "# Commentaire : MAE/RMSE donnent l'erreur moyenne en km. R² indique la part de variance expliquée.\n",
    "\n",
    "# --- 7. Validation Croisée (KFold) ---\n",
    "print(\"\\n--- Validation Croisée (KFold) ---\")\n",
    "# Définir la stratégie de validation croisée (KFold pour la régression)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42) #  suggère StratifiedKFold mais KFold est plus commun pour la régression\n",
    "\n",
    "# Calculer les scores en utilisant R² comme métrique\n",
    "# Note: cross_val_score utilise par défaut le score R² pour les régresseurs\n",
    "cv_scores_r2 = cross_val_score(model_pipeline, X, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Calculer les scores en utilisant l'erreur absolue moyenne négative (plus proche de 0 est mieux)\n",
    "cv_scores_mae = cross_val_score(model_pipeline, X, y, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "print(f\"Scores R² de la validation croisée : {np.round(cv_scores_r2, 3)}\")\n",
    "print(f\"Moyenne R² de la validation croisée : {cv_scores_r2.mean():.3f}\")\n",
    "print(f\"Scores MAE (négatifs) de la validation croisée : {np.round(cv_scores_mae, 2)}\")\n",
    "print(f\"Moyenne MAE de la validation croisée : {-cv_scores_mae.mean():.2f} km\")\n",
    "# Commentaire : La validation croisée donne une estimation plus robuste de la performance du modèle.\n",
    "\n",
    "# --- 8. Visualisation des prédictions vs valeurs réelles (optionnel) ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], '--r', linewidth=2) # Ligne y=x\n",
    "plt.title('Prédictions vs Valeurs Réelles sur l\\'ensemble de test')\n",
    "plt.xlabel('Valeurs Réelles (km)')\n",
    "plt.ylabel('Prédictions (km)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Fin de l'analyse guidée par les instructions du projet ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
